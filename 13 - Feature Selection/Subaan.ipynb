{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection Exercie\n",
    "\n",
    "In this exercise, we will apply Feature Selection to a Iris flowers dataset, where the target variable is the Species. Essentially, our goal is to identify the features that are most relevant in discerning the species of each Iris flower. The dataset is from: https://www.kaggle.com/datasets/uciml/iris\n",
    "You can view the demos found in the repository for some methods.\n",
    "\n",
    "1. Load the dataset from the exercise's Github Repository (Iris.csv)\n",
    "2. Using buisness logic/common sense, drop features that are surely irrevelvant to the target variable.\n",
    "3. Preprocess your data (split data into training and testing)\n",
    "4. Apply feature selection using any 3 (three) different methods:\n",
    "(Hint) Since the target variable, Species, is categorical, you can apply the numerical methods on the numerical predictor variables against themselves instead to reduce Feature redundancy.\n",
    "    - Pearson's correlation coefficient (r)\n",
    "    - Kendall's tau (Ï„)\n",
    "    - Mutual Information (MI)\n",
    "    - Logistic Regression with L1 penalty\n",
    "    - Any other method/model of Feature Selection....\n",
    "6. Compare the results of each feature selection method:\n",
    "    - What features did you manually dropped before applying the feature selection methods? Explain why.\n",
    "    - Are there any common features selected across multiple methods?\n",
    "    - Can you explain why certain features were selected based on their characteristics?\n",
    "(Optional) Visualize the importance of features using techniques like bar charts or heatmaps to make it easier to compare.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
